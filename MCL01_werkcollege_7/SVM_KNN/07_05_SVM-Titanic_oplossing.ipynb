{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Support Vector Machine\n",
    "\n",
    "\n",
    "Voorbeeld oplossing van een klassificatie probleem met ML-model **Support Vector Machine**.\n",
    "\n",
    "Dataset: Titanic \n",
    "- `test.csv`: de testdata set\n",
    "- `train.csv`: de traindata set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All imports:\n",
    "# data analysis and wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helpers\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def load_csv_pd_data(path, filename):\n",
    "    '''\n",
    "    load_csv_pd_data() - construct a pandas DataFrame object \n",
    "           from data in a Excel csv-file `filename`,\n",
    "           stored in a folder `path`.\n",
    "    @returns: a pandas DataFrame\n",
    "    '''\n",
    "    csv_path = os.path.join(path, filename)\n",
    "    # DEBUG: print(csv_path)\n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### De data\n",
    "Er zijn 2 data sets klaar gezet, één om het model te trainen en één om mee te testen. De set om mee te trainen heeft al de overlevings voorspelling per passagier terwijl de test set deze niet heeft "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = load_csv_pd_data('./data/', 'train.csv')\n",
    "test_df = load_csv_pd_data('./data/', 'test.csv')\n",
    "combine= [train_df, test_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PassengerId' 'Survived' 'Pclass' 'Name' 'Sex' 'Age' 'SibSp' 'Parch'\n",
      " 'Ticket' 'Fare' 'Cabin' 'Embarked']\n"
     ]
    }
   ],
   "source": [
    "print(train_df.columns.values)\n",
    "#print('-'*40)\n",
    "#print(test_df.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection\n",
    "\n",
    "In Jupyter notebook `Feature_Selection_analysis_Titanic` is een gedegen analyse gedaan om *features* te selecteren die meegenomen worden in het classificatie probleem wel/niet overleven van de Titanic. De resultaten staan in de volgende cell. Zie voor details de genoemde Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-1026 PP TODO: Fare analysis - checken!! \n",
      "\n",
      "Feature selection done:\n",
      "   Survived  Pclass  Sex  Age  Fare  Embarked  Title  IsAlone  Age*Class\n",
      "0         0       3    0    1     0         0      1        0          3\n",
      "1         1       1    1    2     3         1      3        0          2\n",
      "2         1       3    1    1     1         0      2        1          3\n",
      "3         1       1    1    2     3         0      3        0          2\n",
      "4         0       3    0    2     1         0      1        1          6\n",
      "----------------------------------------\n",
      "   PassengerId  Pclass  Sex  Age  Fare  Embarked  Title  IsAlone  Age*Class\n",
      "0          892       3    0    2     0         2      1        1          6\n",
      "1          893       3    1    2     0         0      3        0          6\n",
      "2          894       2    0    3     1         2      1        1          6\n",
      "3          895       3    0    1     1         0      1        1          3\n",
      "4          896       3    1    1     1         0      3        0          3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hq0132410\\AppData\\Local\\Temp\\ipykernel_12948\\1191931430.py:76: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  train_df[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index=False).mean().sort_values(by='AgeBand', ascending=True)\n",
      "C:\\Users\\hq0132410\\AppData\\Local\\Temp\\ipykernel_12948\\1191931430.py:140: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_df['Fare'].fillna(test_df['Fare'].dropna().median(), inplace=True)\n",
      "C:\\Users\\hq0132410\\AppData\\Local\\Temp\\ipykernel_12948\\1191931430.py:148: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  train_df[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean().sort_values(by='FareBand', ascending=True)\n"
     ]
    }
   ],
   "source": [
    "# ———————————————————————\n",
    "# verwijderen `Cabin` en `Ticket`\n",
    "train_df = train_df.drop(['Ticket', 'Cabin'], axis=1)\n",
    "test_df = test_df.drop(['Ticket', 'Cabin'], axis=1)\n",
    "combine = [train_df, test_df]\n",
    "\n",
    "# ———————————————————————\n",
    "#  Aanmaken nieuwe features title\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "\n",
    "# Een aantal van deze titels samenvoegen:\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n",
    " \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "    \n",
    "train_df[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()\n",
    "\n",
    "# Omzetten van de categorische titel waarden in ordinale waarden:\n",
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset['Title'].map(title_mapping)\n",
    "    dataset['Title'] = dataset['Title'].fillna(0)\n",
    "\n",
    "# train_df.head()\n",
    "\n",
    "# ———————————————————————\n",
    "# Nu het verwijderen van features Name en PassengerId\n",
    "train_df = train_df.drop(['Name', 'PassengerId'], axis=1)\n",
    "test_df = test_df.drop(['Name'], axis=1)\n",
    "combine = [train_df, test_df]\n",
    "\n",
    "# train_df.shape, test_df.shape\n",
    "\n",
    "# ———————————————————————\n",
    "# Sex male/female omzetten in 0/1.\n",
    "for dataset in combine:\n",
    "    dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n",
    "\n",
    "# train_df.head()\n",
    "\n",
    "# ———————————————————————\n",
    "# Aanvullen van ontbrekende waarden Age, Sex and Pclass\n",
    "guess_ages = np.zeros((2,3))\n",
    "\n",
    "for dataset in combine:\n",
    "    for i in range(0, 2):\n",
    "        for j in range(0, 3):\n",
    "            guess_df = dataset[(dataset['Sex'] == i) & \\\n",
    "                                  (dataset['Pclass'] == j+1)]['Age'].dropna()\n",
    "\n",
    "            # age_mean = guess_df.mean()\n",
    "            # age_std = guess_df.std()\n",
    "            # age_guess = rnd.uniform(age_mean - age_std, age_mean + age_std)\n",
    "\n",
    "            age_guess = guess_df.median()\n",
    "\n",
    "            # Convert random age float to nearest .5 age\n",
    "            guess_ages[i,j] = int( age_guess/0.5 + 0.5 ) * 0.5\n",
    "            \n",
    "    for i in range(0, 2):\n",
    "        for j in range(0, 3):\n",
    "            dataset.loc[ (dataset.Age.isnull()) & (dataset.Sex == i) & (dataset.Pclass == j+1),\\\n",
    "                    'Age'] = guess_ages[i,j]\n",
    "                    \n",
    "    dataset['Age'] = dataset['Age'].astype(int)\n",
    "\n",
    "# train_df.head()\n",
    "\n",
    "# Age feature omzetten in een nieuwe AgeBand feature, waarbij de Age wordt ingedeeld in 5 leeftijdsgroepen:\n",
    "train_df['AgeBand'] = pd.cut(train_df['Age'], 5)\n",
    "train_df[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index=False).mean().sort_values(by='AgeBand', ascending=True)\n",
    "\n",
    "# ... en gelijk `Age` omzetten in ordinale waarden:\n",
    "for dataset in combine:    \n",
    "    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n",
    "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
    "    dataset.loc[ dataset['Age'] > 64, 'Age']\n",
    "# train_df.head()\n",
    "\n",
    "# AgeBand was een tijdelijke feature welke we nu niet meer nodig hebben:\n",
    "train_df = train_df.drop(['AgeBand'], axis=1)\n",
    "combine = [train_df, test_df]\n",
    "# train_df.head()\n",
    "\n",
    "# ———————————————————————\n",
    "# Toevoegen van een nieuwe feature `FamilySize`\n",
    "for dataset in combine:\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "\n",
    "train_df[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n",
    "\n",
    "# toevoegen we een feature `IsAlone` om aan te geven \n",
    "# of een persoon alléén op de boot zit of niet:\n",
    "for dataset in combine:\n",
    "    dataset['IsAlone'] = 0\n",
    "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "\n",
    "train_df[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).mean()\n",
    "\n",
    "# De nieuwe feature `IsAlone` gebruiken in plaats van \n",
    "# `FamilySize`, `Parch` en `SibSp`, welke we ook uit \n",
    "# de set verwijderen:\n",
    "train_df = train_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\n",
    "test_df = test_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\n",
    "combine = [train_df, test_df]\n",
    "# train_df.head()\n",
    "\n",
    "# ———————————————————————\n",
    "# toevoegen `Age*Class`\n",
    "for dataset in combine:\n",
    "    dataset['Age*Class'] = dataset.Age * dataset.Pclass\n",
    "\n",
    "train_df.loc[:, ['Age*Class', 'Age', 'Pclass']].head(10)\n",
    "\n",
    "# ———————————————————————\n",
    "# Embarked's ontbrekende waarden aanvullen:\n",
    "freq_port = train_df.Embarked.dropna().mode()[0]\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna(freq_port)\n",
    "    \n",
    "train_df[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n",
    "\n",
    "# categorische waarden in `Embarked` omzetten naar numeriek:\n",
    "for dataset in combine:\n",
    "    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
    "\n",
    "# train_df.head()\n",
    "\n",
    "# ———————————————————————\n",
    "# Aanvullen van `Fare` met de mediaan:\n",
    "print(\"2022-1026 PP TODO: Fare analysis - checken!! \")\n",
    "test_df['Fare'].fillna(test_df['Fare'].dropna().median(), inplace=True)\n",
    "# 2022-1026 PP: moet vorige regel niet zijn de volgende:\n",
    "# for dataset in combine:\n",
    "#     dataset['Fare'].fillna(dataset['Fare'].dropna().median(), inplace=True)\n",
    "# test_df.head()\n",
    "\n",
    "# Voor Fare gaan we een bandbreedte definieren:\n",
    "train_df['FareBand'] = pd.qcut(train_df['Fare'], 4)\n",
    "train_df[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean().sort_values(by='FareBand', ascending=True)\n",
    "\n",
    "# ... en omzetten naar numerieke waarden:\n",
    "for dataset in combine:\n",
    "    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n",
    "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
    "    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "\n",
    "train_df = train_df.drop(['FareBand'], axis=1)\n",
    "combine = [train_df, test_df]\n",
    "#train_df.head(10)\n",
    "# En ook de test set:\n",
    "#test_df.head(10)\n",
    "\n",
    "# ———————————————————————\n",
    "print('\\nFeature selection done:')\n",
    "print(train_df.head())\n",
    "print('-'*40)\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We zijn er ...\n",
    "\n",
    "Het heeft even geduurd maar eindelijk zijn de datasets klaar om te gebruiken voor een voorspelling.\n",
    "\n",
    "Check punten dataset (train en test) dat:\n",
    "- testdata is exclusief `survived`\n",
    "- alle waarden (train en test) numeriek zijn.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((891, 8), (891,), (418, 8))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# splits features and targets\n",
    "X_train = train_df.drop(\"Survived\", axis=1)\n",
    "Y_train = train_df[\"Survived\"]\n",
    "X_test  = test_df.drop(\"PassengerId\", axis=1).copy()\n",
    "X_train.shape, Y_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We gebruiken nog eerst een regressie voor het valideren van onze aannames voor het aanmaken van nieuwe features en om een overzicht te krijgen welke features sterk bijdragen aan het wel of niet overleven."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sex</td>\n",
       "      <td>2.201445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Title</td>\n",
       "      <td>0.397484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.286911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Embarked</td>\n",
       "      <td>0.261583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>IsAlone</td>\n",
       "      <td>0.126942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fare</td>\n",
       "      <td>-0.086368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Age*Class</td>\n",
       "      <td>-0.310963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pclass</td>\n",
       "      <td>-0.750392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Feature  Correlation\n",
       "1        Sex     2.201445\n",
       "5      Title     0.397484\n",
       "2        Age     0.286911\n",
       "4   Embarked     0.261583\n",
       "6    IsAlone     0.126942\n",
       "3       Fare    -0.086368\n",
       "7  Age*Class    -0.310963\n",
       "0     Pclass    -0.750392"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(solver=\"lbfgs\")\n",
    "logreg.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = logreg.predict(X_test)\n",
    "acc_log = round(logreg.score(X_train, Y_train) * 100, 2)\n",
    "acc_log\n",
    "\n",
    "coeff_df = pd.DataFrame(train_df.columns.delete(0))\n",
    "coeff_df.columns = ['Feature']\n",
    "coeff_df[\"Correlation\"] = pd.Series(logreg.coef_[0])\n",
    "\n",
    "coeff_df.sort_values(by='Correlation', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hierboven is te zien dat als de waarde van `Sex` verhoogt (0/man naar 1/vrouw), de survival rate het sterkste toeneemt (kans op overleven). Andersom, als de waarde voor `Pclass` hoger wordt, dan wordt neemt de overlevingskans het sterkste af. De zelf toegevoegde feature `Age*Class` is ook een goede (negatieve) voorspeller voor de overlevingskans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines\n",
    "\n",
    "Nu de voorspelling met lineaire SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78.68\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(kernel='linear')\n",
    "#svc = SVC(kernel=\"rbf\", gamma=\"auto\")\n",
    "# 'rbf' geeft iets grotere score (83%)\n",
    "\n",
    "svc.fit(X_train, Y_train)  # train\n",
    "\n",
    "Y_train_pred=svc.predict(X_train)  # voorspellen\n",
    "Y_pred = svc.predict(X_test)  # testen\n",
    "\n",
    "acc_svc = round(svc.score(X_train, Y_train) * 100, 2)\n",
    "print (acc_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mogelijk volgende stappen\n",
    "\n",
    "- Verbeteren van bovenstaande oplossing.\n",
    "- Denk dan aan het toepassen van cross validation.\n",
    "- Denk dan aan parameter tuning.\n",
    "- Andere (SVG)kernels?\n",
    "- Zou jij de ontbrekende data op een andere manier aanvullen?\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
